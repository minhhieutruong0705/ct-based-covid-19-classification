{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19_Phase2_Utils_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnViarIJbtvE"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8-g0QcOZ_qj"
      },
      "source": [
        "class DiceBCEWithLogisticLoss(nn.Module):\n",
        "  def __init__(self, weight=None, reduction='mean', BCE_weight=0.4):\n",
        "    super(DiceBCEWithLogisticLoss, self).__init__()\n",
        "    self.reduction = reduction\n",
        "    self.BCE_weight = BCE_weight\n",
        "\n",
        "  def forward(self, inputs, targets):\n",
        "    logits = inputs  \n",
        "    inputs = torch.sigmoid(inputs) \n",
        "\n",
        "    assert inputs.size() == targets.size()\n",
        "\n",
        "    # inputs = inputs.view(-1)\n",
        "    # targets = targets.view(-1)\n",
        "    \n",
        "    intersection = (inputs * targets).sum()\n",
        "    union = inputs.sum() + targets.sum()               \n",
        "    \n",
        "    dice_loss = 1 - ((2.*intersection) / (union))  \n",
        "    BCE_loss = F.binary_cross_entropy_with_logits(\n",
        "        input=logits,\n",
        "        target=targets,\n",
        "        reduction=self.reduction\n",
        "    )\n",
        "    Dice_BCE = BCE_loss * self.BCE_weight + dice_loss\n",
        "    return Dice_BCE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxpqo0Z366VC"
      },
      "source": [
        "class CustomAccuracyLoss(nn.Module):\n",
        "  def __init__(self, tn_weight=0.2):\n",
        "    super(CustomAccuracyLoss, self).__init__()\n",
        "    self.tn_weight = tn_weight\n",
        "\n",
        "  def forward(self, inputs, targets):  \n",
        "    inputs = torch.sigmoid(inputs) \n",
        "\n",
        "    assert inputs.size() == targets.size()\n",
        "\n",
        "    # inputs = inputs.view(-1)\n",
        "    # targets = targets.view(-1)\n",
        "    \n",
        "    tp = (inputs * targets).sum()\n",
        "    tn = ((1 - inputs).abs() * (1 - targets).abs()).sum()\n",
        "    fp = (inputs * (1 - targets).abs()).sum()\n",
        "    fn = ((1 - inputs).abs() * targets).sum()\n",
        "\n",
        "    tn_w = tn*self.tn_weight\n",
        "\n",
        "    accuracy = (tp + tn_w)/(tp + tn + fp + fn)\n",
        "\n",
        "    ratio = (tn + fp)/(tp + fn)\n",
        "    max = (1 + self.tn_weight*ratio)/(1 + ratio)\n",
        "\n",
        "    accuracy_loss = 1 - accuracy/max\n",
        "    return accuracy_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcpB2k4Z6w_i"
      },
      "source": [
        "class FocalTverskyLoss(nn.Module):\n",
        "  def __init__(self, alpha=0.7, gamma=0.75, smooth=1.):\n",
        "    super(FocalTverskyLoss, self).__init__()\n",
        "    self.alpha = alpha\n",
        "    self.beta = 1 - self.alpha\n",
        "    self.gamma = gamma\n",
        "    self.smooth = smooth\n",
        "\n",
        "  def forward(self, inputs, targets):  \n",
        "    inputs = torch.sigmoid(inputs) \n",
        "\n",
        "    assert inputs.size() == targets.size()\n",
        "\n",
        "    # inputs = inputs.view(-1)\n",
        "    # targets = targets.view(-1)\n",
        "    \n",
        "    tp = (inputs * targets).sum()\n",
        "    tn = ((1 - inputs).abs() * (1 - targets).abs()).sum()\n",
        "    fp = (inputs * (1 - targets).abs()).sum()\n",
        "    fn = ((1 - inputs).abs() * targets).sum()\n",
        "    \n",
        "    tversky = (tp + self.smooth) / (tp + self.alpha*fn + self.beta*fp + self.smooth)\n",
        "    tversky_loss = 1 - tversky\n",
        "\n",
        "    focal_tversky = torch.pow(tversky_loss, self.gamma)\n",
        "    return focal_tversky"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkXQW0NP1T8L"
      },
      "source": [
        "def train_incorporate(\n",
        "    loader, \n",
        "    model, \n",
        "    optimizer_class, \n",
        "    optimizer_mask, \n",
        "    loss_fn_class, \n",
        "    loss_fn_mask, \n",
        "    scaler, \n",
        "    device, \n",
        "    # weight_class=1, \n",
        "    # weight_mask=1\n",
        "  ):\n",
        "  # batch_size = loader.batch_size\n",
        "  # dataset_size = len(loader.dataset)\n",
        "  total_train_loss_class = total_train_loss_mask = 0\n",
        "  tp = tn = fp = fn = 0\n",
        "  num_correct = num_pixels = 0\n",
        "  dice_score = count_dice = 0\n",
        "  \n",
        "  loop = tqdm(loader)\n",
        "  model.train()\n",
        "\n",
        "  for batch_index, (image, label, mask) in enumerate(loop):\n",
        "    data = image.to(device)\n",
        "\n",
        "    label = label.long().to(device)\n",
        "    filter = label.reshape(-1, 1)\n",
        "    target_mask = mask.float().unsqueeze(1).to(device)\n",
        "\n",
        "    optimizer_mask.zero_grad()\n",
        "    optimizer_class.zero_grad()\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "      output_class, output_mask = model(data)\n",
        "      target_class = torch.zeros_like(output_class, device=device)\n",
        "      target_class[np.arange(data.size(0)), label] = 1\n",
        "      loss_mask = loss_fn_mask(output_mask[filter==1], target_mask[filter==1])\n",
        "      # loss_mask = loss_fn_mask(output_mask, target_mask)\n",
        "      loss_class = loss_fn_class(output_class, target_class)\n",
        "      # loss = loss_class * weight_class + loss_mask * weight_mask\n",
        "\n",
        "    scaler.scale(loss_mask).backward(retain_graph=True)\n",
        "    scaler.scale(loss_class).backward()\n",
        "\n",
        "    scaler.step(optimizer_mask)\n",
        "    scaler.step(optimizer_class)\n",
        "\n",
        "    scaler.update()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction_class = output_class.argmax(dim=1, keepdim=True)\n",
        "      # accuracy_class = prediction_class.eq(label.view_as(prediction_class)).sum()\n",
        "\n",
        "      truth_class = label.view_as(prediction_class)\n",
        "      tp += (prediction_class * truth_class).sum()\n",
        "      tn += ((1 - prediction_class).abs() * (1 - truth_class).abs()).sum()\n",
        "      fp += (prediction_class * (1 - truth_class).abs()).sum()\n",
        "      fn += ((1 - prediction_class).abs() * truth_class).sum()\n",
        "\n",
        "      prediction_mask = torch.sigmoid(output_mask)\n",
        "      prediction_mask = (prediction_mask > 0.5).float()\n",
        "\n",
        "      # #### save for investigation\n",
        "      # torchvision.utils.save_image(prediction_mask, f\"test/preds/pred_{batch_index}.jpg\")\n",
        "      # torchvision.utils.save_image(target_mask, f\"test/labels/label_{batch_index}.jpg\")\n",
        "\n",
        "      num_correct += (prediction_mask[truth_class==1] == target_mask[truth_class==1]).sum()\n",
        "      num_pixels += torch.numel(prediction_mask[truth_class==1])\n",
        "      if torch.sum(truth_class==1) > 0:\n",
        "        dice_score += (2 * (prediction_mask[truth_class==1] * target_mask[truth_class==1]).sum()) / ((prediction_mask[truth_class==1] + target_mask[truth_class==1]).sum())\n",
        "        # count_dice += torch.sum(truth_class==1)\n",
        "        count_dice += 1\n",
        "\n",
        "    loss_item_class = loss_class.item()\n",
        "    loss_item_mask = loss_mask.item()\n",
        "\n",
        "    loss = loss_item_class + loss_item_mask\n",
        "\n",
        "    loop.set_postfix(loss_class=loss_item_class, loss_mask=loss_item_mask)  \n",
        "\n",
        "    total_train_loss_class += loss_item_class\n",
        "    total_train_loss_mask += loss_item_mask\n",
        "\n",
        "  percision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "  f1 = 2 * percision * recall / (percision + recall) \n",
        "  accuracy_class = (tp + tn) / (tp + tn + fp + fn) * 100\n",
        "  dice_class = tp / (fp + fn + tp) * 100\n",
        "\n",
        "  accuracy_mask = num_correct / num_pixels * 100\n",
        "  dice_mask = dice_score / count_dice * 100\n",
        "\n",
        "  print(\"\\n[TRAIN]\")\n",
        "  print(f\"[Classification]: Loss: {total_train_loss_class/len(loader):.6f}, Dice: {dice_class:2f}, Acc: {accuracy_class:2f}, F1: {f1:2f},\")\n",
        "  print(f\"[Segmentation]:   Loss: {total_train_loss_mask/len(loader):.6f}, Dice: {dice_mask:2f},  Acc: {accuracy_mask:2f}\")\n",
        "  print(f\"[Confusion]:      TP: {tp.item()}, TN: {tn.item()}, FP: {fp.item()}, FN: {fn.item()}\")\n",
        "\n",
        "  return total_train_loss_class/len(loader), total_train_loss_mask/len(loader), accuracy_class, accuracy_mask, dice_class, dice_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HwnQ9lGV9vC"
      },
      "source": [
        "def train_single(loader, model, optimizer, loss_fn, scaler, device):\n",
        "  total_train_loss = 0\n",
        "  tp = tn = fp = fn = 0\n",
        "  \n",
        "  loop = tqdm(loader)\n",
        "  model.train()\n",
        "\n",
        "  for batch_index, (image, label, mask) in enumerate(loop):\n",
        "    data = image.to(device)\n",
        "    label = label.long().to(device)\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "      output_class = model(data)\n",
        "      target_class = torch.zeros_like(output_class, device=device)\n",
        "      target_class[np.arange(data.size(0)), label] = 1\n",
        "      loss_class = loss_fn(output_class, target_class)\n",
        "      loss = loss_class\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction_class = output_class.argmax(dim=1, keepdim=True)\n",
        "\n",
        "      truth_class = label.view_as(prediction_class)\n",
        "      tp += (prediction_class * truth_class).sum()\n",
        "      tn += ((1 - prediction_class).abs() * (1 - truth_class).abs()).sum()\n",
        "      fp += (prediction_class * (1 - truth_class).abs()).sum()\n",
        "      fn += ((1 - prediction_class).abs() * truth_class).sum()\n",
        "\n",
        "    loop.set_postfix(loss=loss.item())  \n",
        "    total_train_loss += loss.item() \n",
        "\n",
        "  percision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "\n",
        "  f1 = 2 * percision * recall / (percision + recall) \n",
        "  accuracy_class = (tp + tn) / (tp + tn + fp + fn) * 100\n",
        "  dice_class = tp / (fp + fn + tp) * 100\n",
        "\n",
        "  print(\"\\n[TRAIN]:         Training Loss: {:.6f}\".format(total_train_loss / len(loader)))\n",
        "  print(f\"[Classification]: Dice: {dice_class:2f}, Acc: {accuracy_class:2f}, F1: {f1:2f},\")\n",
        "  print(f\"[Confusion]:      TP: {tp.item()}, TN: {tn.item()}, FP: {fp.item()}, FN: {fn.item()}\")\n",
        "\n",
        "  loss_mask = accuracy_mask = dice_mask = 0\n",
        "  \n",
        "  return total_train_loss/len(loader), loss_mask, accuracy_class, accuracy_mask, dice_class, dice_mask"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
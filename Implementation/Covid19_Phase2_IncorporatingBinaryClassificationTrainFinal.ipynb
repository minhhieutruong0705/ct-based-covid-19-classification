{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19_Phase2_IncorporatingBinaryClassificationTrainFinal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWZcnxD4c81a"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpt9BvCv1qU1"
      },
      "source": [
        "# !pip install import-ipynb\n",
        "# !pip install albumentations==0.4.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHACXFYQ1xOv"
      },
      "source": [
        "# !cp '/content/drive/MyDrive/Colab Notebooks/Covid19/Phase2_IncorporatingBinaryClassification/Covid19_Phase2_HUUtils.ipynb' .\n",
        "# !cp '/content/drive/MyDrive/Colab Notebooks/Covid19/Covid19_CustomCrAsppReUNet.ipynb' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJdDe6sntTr8"
      },
      "source": [
        "%cd ~/Minh\\ Hieu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWsineKAOtMx"
      },
      "source": [
        "# saving_directory = \"/content/drive/MyDrive/Colab Notebooks/Covid19/Phase2_IncorporatingBinaryClassification/Output/LamdaNetCustom\"\n",
        "\n",
        "# saving_directory = \"Output/CRNetPNG_NOLung_314E\"\n",
        "# saving_directory = \"Output/CRNetPNG_NOLung_314E512\"\n",
        "# saving_directory = \"Output/CRNetPNG_YESLung_314E\"\n",
        "\n",
        "# saving_directory = \"Output/CRNetPNG_YESLung_314E_CAP\"\n",
        "\n",
        "# saving_directory = \"Output/CRNetHU_NOLung_314E\"\n",
        "# saving_directory = \"Output/CRNetHU_YESLung_314E512\"\n",
        "\n",
        "# saving_directory = \"Output/CutomCrAsppReUNetHU_YESLung_108E\"\n",
        "# saving_directory = \"Output/CutomCrAsppReUNetPNG_YESLung_108E\"\n",
        "\n",
        "# saving_directory = \"Output/CutomCrAsppReUNetPNG_YESLung_108E_CAP\"\n",
        "# saving_directory = \"Output/CutomCrAsppReUNetPNG_YESLung_108E_CAP\"\n",
        "\n",
        "# saving_directory = \"Output/OriginCrAsppReUNetHU_YESLung_108E\"\n",
        "# saving_directory = \"Output/OriginCrAsppReUNetPNG_YESLung_108E\"\n",
        "\n",
        "# epochs = 50\n",
        "# epochs = 108\n",
        "# epochs = 314\n",
        "#######################################################################################\n",
        "\n",
        "# saving_directory = \"Final_Output/XNet_PNG_256\"                      ## 450   \n",
        "# saving_directory = \"Final_Output/OriginalIncoNet_PNG_256\"           ## 450    \n",
        "# saving_directory = \"Final_Output/XNet_HU_256\"                       ## 450\n",
        "# saving_directory = \"Final_Output/OriginalIncoNet_HU_256\"            ## 450     \n",
        "\n",
        "# saving_directory = \"Final_Output/XNet_CAP_HU_256\"                   ## 450   \n",
        "# saving_directory = \"Final_Output/XNet_CAP_PNG_256\"                  ## 450   \n",
        "\n",
        "# saving_directory = \"Final_Output/CRNet_HU_256\"                      ## 450\n",
        "# saving_directory = \"Final_Output/CRNet_PNG_256\"                     ## 450 \n",
        "\n",
        "saving_directory = \"Final_Output/XNet_512\"                          ## 450 \n",
        "\n",
        "\n",
        "epochs = 450\n",
        "start_epoch = 0         #if resume training, change to the last training index\n",
        "\n",
        "is_load_to_ram = False  #load training data to RAM\n",
        "is_continue = False     #resume trainning\n",
        "\n",
        "is_HU = True            #HU or 255 (DICOM or PNG)\n",
        "HU_range = 900.0        #from -1000 to -100\n",
        "is_concat_lung = True   #keep as True (False for NO concatenation of lung masks)\n",
        "is_full_size = True     #512 or 256\n",
        "is_cap = False          #classification with CAP or healthy cases\n",
        "\n",
        "# #uncomment to select model \n",
        "# model_name = \"crnet\"                  #CRNet\n",
        "# model_name = \"crasppreunet\"           #CR-IM\n",
        "model_name = \"crasppreunet_custom\"    #CR-IM-SCRC\n",
        "\n",
        "# model_name = \"densenet\"\n",
        "# is_pretrained = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDPmV38hjAsf"
      },
      "source": [
        "import albumentations as A\n",
        "import import_ipynb\n",
        "import torch\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from Covid19_Phase2_Utils_EvalTest import evaluate_model_incorporate, evaluate_model_single, save_checkpoint, load_checkpoint, log_epoch, log_train\n",
        "from Covid19_Phase2_Utils_Dataset import get_png_data_loader, get_hu_data_loader\n",
        "from Covid19_Phase2_Utils_Train import DiceBCEWithLogisticLoss, CustomAccuracyLoss, FocalTverskyLoss, train_single, train_incorporate\n",
        "from Covid19_CRNet import CRNet\n",
        "from Covid19_CrAsppReUNet import CRASPPReUNet\n",
        "# from Covid19_CustomCrAsppReUNet import CustomCRASPPReUNet\n",
        "from Covid19_CustomFinalCrAsppReUNet import CustomFinalCRASPPReUNet\n",
        "import torchvision.models as models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo7LVMgmDE-3"
      },
      "source": [
        "def load_densenet(pretrained=False):\n",
        "  print(f\"Model Pretrained is {pretrained}\")\n",
        "  model = models.densenet169(pretrained=pretrained)\n",
        "  num_feature = model.classifier.in_features\n",
        "  model.classifier = nn.Linear(num_feature, 2)\n",
        "  return model.cuda(), \"single\"  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWulJZOn_fCV"
      },
      "source": [
        "def load_crnet():\n",
        "  model = CRNet(img_dimwh=height_crop, in_channels=in_channels)\n",
        "  return model.cuda(), \"single\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffTrLuysDIqV"
      },
      "source": [
        "def load_crasppreunet():\n",
        "  model = CRASPPReUNet(img_dimwh=height_crop, in_channels=in_channels)\n",
        "  return model.cuda(), \"incorporate\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jlAW-nV-Ete"
      },
      "source": [
        "def load_crasppreunet_custom():\n",
        "  model = CustomFinalCRASPPReUNet(img_dimwh=height_crop, in_channels=in_channels)\n",
        "  return model.cuda(), \"incorporate\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-xwNSduWVnu"
      },
      "source": [
        "def init_weights(module):\n",
        "  if type(module) == nn.Linear or\\\n",
        "    type(module) == nn.Conv2d or\\\n",
        "    type(module) == nn.ConvTranspose2d:\n",
        "    torch.nn.init.kaiming_normal_(module.weight)\n",
        "  elif type(module) == nn.BatchNorm2d:\n",
        "    nn.init.ones_(module.weight)\n",
        "    nn.init.zeros_(module.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLEyI7LYn1f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1673d372-9df3-42fc-df04-5e91fdee8c88"
      },
      "source": [
        "checkpoint_path = saving_directory + \"/checkpoint.pth.tar\"\n",
        "train_log_filename = saving_directory + \"/train_log\"\n",
        "\n",
        "if not is_HU:\n",
        "  covid_dir = 'Dataset_PNG/COVID'\n",
        "  nonCovid_dir = 'Dataset_PNG/NONCOVID'\n",
        "else:\n",
        "  covid_dir = 'zip/Dataset/COVID'\n",
        "  nonCovid_dir = 'zip/Dataset/NONCOVID'\n",
        "\n",
        "if not is_full_size:\n",
        "  height = width = 256\n",
        "  height_crop = width_crop= 224\n",
        "  blur_kernel = 5\n",
        "else:\n",
        "  height = width = 512\n",
        "  height_crop = width_crop= 448\n",
        "  blur_kernel = 7\n",
        "\n",
        "rotation_limit = 15\n",
        "mean = [0.0, 0.0, 0.0]\n",
        "std = [1.0, 1.0, 1.0]\n",
        "random_crop_scale = 0.8\n",
        "max_pixel_value = 255.0\n",
        "contrast_factor = brightness_factor = 0.2\n",
        "\n",
        "batch_size = 16\n",
        "# batch_size = 64\n",
        "learning_rate_class = 1e-4\n",
        "learning_rate_mask = 1e-5\n",
        "reduction = 'mean'\n",
        "# reduction = 'sum'\n",
        "scheduler_period_class = 10\n",
        "scheduler_period_mask = 10\n",
        "if is_concat_lung:\n",
        "  in_channels = 4\n",
        "else:\n",
        "  in_channels = 3\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"[INFO] Using \" + device + \" for training ...\")\n",
        "\n",
        "if not is_HU:\n",
        "  if not is_cap:\n",
        "    train_list_COVID = 'Dataset_PNG/covid_train.txt'\n",
        "    train_list_NonCOVID = 'Dataset_PNG/normal_train.txt'\n",
        "\n",
        "    val_list_COVID = \"Dataset_PNG/covid_validation.txt\"\n",
        "    val_list_NonCOVID = \"Dataset_PNG/normal_validation.txt\"\n",
        "\n",
        "    test_list_COVID = \"Dataset_PNG/covid_test.txt\"\n",
        "    test_list_NonCOVID = \"Dataset_PNG/normal_test.txt\"\n",
        "  else:\n",
        "    print(\"[INFO] CAP\")\n",
        "    train_list_COVID = 'Dataset_PNG/covid_train.txt'\n",
        "    train_list_NonCOVID = 'Dataset_PNG/cap_train.txt'\n",
        "\n",
        "    val_list_COVID = \"Dataset_PNG/covid_validation.txt\"\n",
        "    val_list_NonCOVID = \"Dataset_PNG/cap_validation.txt\"\n",
        "\n",
        "    test_list_COVID = \"Dataset_PNG/covid_test.txt\"\n",
        "    test_list_NonCOVID = \"Dataset_PNG/cap_test.txt\"\n",
        "else:\n",
        "  if not is_cap:\n",
        "    # train_list_COVID = 'zip/Dataset/covid_train (copy).txt'       #small set for testing convergence\n",
        "    # train_list_NonCOVID = 'zip/Dataset/normal_train (copy).txt'   #small set for testing convergence\n",
        "    train_list_COVID = 'zip/Dataset/covid_train.txt'\n",
        "    train_list_NonCOVID = 'zip/Dataset/normal_train.txt'\n",
        "\n",
        "    val_list_COVID = \"zip/Dataset/covid_validation.txt\"\n",
        "    val_list_NonCOVID = \"zip/Dataset/normal_validation.txt\"\n",
        "\n",
        "    test_list_COVID = \"zip/Dataset/covid_test.txt\"\n",
        "    test_list_NonCOVID = \"zip/Dataset/normal_test.txt\"\n",
        "  else:\n",
        "    print(\"[INFO] CAP\")   \n",
        "    train_list_COVID = 'zip/Dataset/covid_train.txt'\n",
        "    train_list_NonCOVID = 'zip/Dataset/cap_train.txt'\n",
        "\n",
        "    val_list_COVID = \"zip/Dataset/covid_validation.txt\"\n",
        "    val_list_NonCOVID = \"zip/Dataset/cap_validation.txt\"\n",
        "\n",
        "    test_list_COVID = \"zip/Dataset/covid_test.txt\"\n",
        "    test_list_NonCOVID = \"zip/Dataset/cap_test.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Using cuda:0 for training ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C52H1C6JP8WY"
      },
      "source": [
        "if not is_HU:\n",
        "  train_transformer = A.Compose([\n",
        "    A.Resize(height=height, width=width, interpolation=cv2.INTER_AREA),\n",
        "    A.RandomResizedCrop(height=height_crop, width=width_crop, scale=(random_crop_scale, 1.0), interpolation=cv2.INTER_AREA),\n",
        "    A.HorizontalFlip(),\n",
        "    A.Rotate(limit=rotation_limit),\n",
        "    A.GaussNoise(),\n",
        "    A.GaussianBlur(blur_limit=blur_kernel),\n",
        "    A.RandomContrast(limit=contrast_factor),\n",
        "    A.RandomBrightness(limit=brightness_factor),\n",
        "    A.Normalize(\n",
        "        mean=mean,\n",
        "        std=std,\n",
        "        max_pixel_value=max_pixel_value,\n",
        "    ),\n",
        "    ToTensorV2()\n",
        "    ],\n",
        "    additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
        "    )\n",
        "  \n",
        "  val_transformer = A.Compose([\n",
        "  A.Resize(height=height_crop, width=width_crop),\n",
        "  A.CenterCrop(height=height_crop, width=width_crop),\n",
        "  A.Normalize(\n",
        "      mean=mean,\n",
        "      std=std,\n",
        "      max_pixel_value=max_pixel_value,\n",
        "  ),\n",
        "  ToTensorV2()\n",
        "  ],\n",
        "  additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
        "  )\n",
        "else:\n",
        "  train_transformer = A.Compose([\n",
        "    A.ToFloat(max_value=HU_range),\n",
        "    A.Resize(height=height, width=width, interpolation=cv2.INTER_AREA),\n",
        "    A.RandomResizedCrop(height=height_crop, width=width_crop, scale=(random_crop_scale, 1.0), interpolation=cv2.INTER_AREA),\n",
        "    A.HorizontalFlip(),\n",
        "    A.Rotate(limit=rotation_limit),\n",
        "    A.GaussianBlur(blur_limit=blur_kernel),\n",
        "    A.RandomContrast(limit=contrast_factor),\n",
        "    A.RandomBrightness(limit=brightness_factor),\n",
        "    ToTensorV2()\n",
        "    ],\n",
        "    additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
        "    )\n",
        "\n",
        "  val_transformer = A.Compose([\n",
        "    A.ToFloat(max_value=HU_range),\n",
        "    A.Resize(height=height_crop, width=width_crop),\n",
        "    A.CenterCrop(height=height_crop, width=width_crop),\n",
        "    ToTensorV2()\n",
        "    ],\n",
        "    additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0kA9Lg61hSN"
      },
      "source": [
        "if model_name == \"densenet\":\n",
        "  model, mode = load_densenet(pretrained=is_pretrained)\n",
        "if model_name == \"crnet\":\n",
        "  model, mode = load_crnet()\n",
        "if model_name == \"crasppreunet\":\n",
        "  model, mode = load_crasppreunet()\n",
        "if model_name == \"crasppreunet_custom\":\n",
        "  model, mode = load_crasppreunet_custom()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIagxGK2Kjp5"
      },
      "source": [
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOHGnSFl4wMJ"
      },
      "source": [
        "# loss_fn_class = nn.BCEWithLogitsLoss(reduction=reduction).cuda()\n",
        "loss_fn_class = DiceBCEWithLogisticLoss(reduction=reduction).cuda()\n",
        "# loss_fn_mask = nn.BCEWithLogitsLoss(reduction=reduction).cuda()\n",
        "# loss_fn_mask = DiceBCEWithLogisticLoss(reduction=reduction).cuda()\n",
        "# loss_fn_mask = CustomAccuracyLoss().cuda()\n",
        "loss_fn_mask = FocalTverskyLoss().cuda()\n",
        "optimizer_class = optim.Adam(model.parameters(), lr=learning_rate_class)\n",
        "optimizer_mask = optim.Adam(model.parameters(), lr=learning_rate_mask)\n",
        "scheduler_class = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer_class, T_max=scheduler_period_class)\n",
        "scheduler_mask = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer_mask, T_max=scheduler_period_mask)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNENHyoTwggB"
      },
      "source": [
        "if not is_HU:\n",
        "  train_loader, val_loader, test_loader = get_png_data_loader(\n",
        "      covid_dir=covid_dir,\n",
        "      nonCovid_dir=nonCovid_dir,\n",
        "      train_list_COVID=train_list_COVID,\n",
        "      train_list_NonCOVID=train_list_NonCOVID,\n",
        "      train_transformer=train_transformer,\n",
        "      val_list_COVID=val_list_COVID,\n",
        "      val_list_NonCOVID=val_list_NonCOVID,\n",
        "      val_transformer=val_transformer,\n",
        "      test_list_COVID=test_list_COVID,\n",
        "      test_list_NonCOVID=test_list_NonCOVID,\n",
        "      batch_size=batch_size,\n",
        "      is_load_to_ram=is_load_to_ram,\n",
        "      is_concat_lung=is_concat_lung,\n",
        "      is_cap=is_cap\n",
        "  )\n",
        "else:\n",
        "  train_loader, val_loader, test_loader = get_hu_data_loader(\n",
        "      covid_dir=covid_dir,\n",
        "      nonCovid_dir=nonCovid_dir,\n",
        "      train_list_COVID=train_list_COVID,\n",
        "      train_list_NonCOVID=train_list_NonCOVID,\n",
        "      train_transformer=train_transformer,\n",
        "      val_list_COVID=val_list_COVID,\n",
        "      val_list_NonCOVID=val_list_NonCOVID,\n",
        "      val_transformer=val_transformer,\n",
        "      test_list_COVID=test_list_COVID,\n",
        "      test_list_NonCOVID=test_list_NonCOVID,\n",
        "      batch_size=batch_size,\n",
        "      is_load_to_ram=is_load_to_ram,\n",
        "      is_concat_lung=is_concat_lung,\n",
        "      is_cap=is_cap\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N5BDBCPpf6Z"
      },
      "source": [
        "start = 0\n",
        "if is_continue:\n",
        "  load_checkpoint(torch.load(checkpoint_path.replace(\".pth.tar\", str(start_epoch - 1) + \".pth.tar\")), model, optimizer_class, optimizer_class)\n",
        "  start = start_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLnHOnmmWgLV"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YwNRU1WcKoH"
      },
      "source": [
        "# train\n",
        "for epoch in range(start, epochs):\n",
        "  print(\"\\nEpoch:\", epoch)\n",
        "  if mode == \"incorporate\":\n",
        "    loss_class, loss_mask, accuracy_class, accuracy_mask, dice_class, dice_mask = train_incorporate(\n",
        "        loader=train_loader, \n",
        "        model=model,\n",
        "        optimizer_class=optimizer_class,\n",
        "        optimizer_mask=optimizer_mask, \n",
        "        loss_fn_class=loss_fn_class,\n",
        "        loss_fn_mask=loss_fn_mask, \n",
        "        scaler=scaler, \n",
        "        device=device)\n",
        "  if mode == \"single\":\n",
        "    loss_class, loss_mask, accuracy_class, accuracy_mask, dice_class, dice_mask = train_single(\n",
        "        loader=train_loader, \n",
        "        model=model,\n",
        "        optimizer=optimizer_class,\n",
        "        loss_fn=loss_fn_class,\n",
        "        scaler=scaler, \n",
        "        device=device)\n",
        "  log_train(epoch, loss_class, loss_mask, accuracy_class, accuracy_mask, dice_class, dice_mask, train_log_filename)\n",
        "  \n",
        "  if mode == \"incorporate\":\n",
        "    f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_incorporate(loader=val_loader, model=model, device=device)\n",
        "  if mode == \"single\":\n",
        "    f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_single(loader=val_loader, model=model, device=device)\n",
        "\n",
        "  log_epoch(\"EVAL\", epoch, accuracy_class, f1, dice_class, accuracy_mask, dice_mask, train_log_filename)\n",
        "  checkpoint = {\n",
        "      \"epoch\": epoch,\n",
        "      \"state_dict\": model.state_dict(),\n",
        "      \"optimizer_class\": optimizer_class.state_dict(),\n",
        "      \"optimizer_mask\": optimizer_mask.state_dict()\n",
        "  }\n",
        "  save_checkpoint(state=checkpoint, checkpoint_filename=checkpoint_path, checkpoint_index=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0vO7ZMWXbAN"
      },
      "source": [
        "# test\n",
        "best_socre = 0\n",
        "best_model_index = 0\n",
        "f = open(train_log_filename, 'a+')\n",
        "f.write(\"\\n ###Test###\")\n",
        "f.close()\n",
        "\n",
        "# for i in range(epochs):\n",
        "for i in range(start, epochs):\n",
        "  print(\"\\nEpoch:\", i)\n",
        "  load_checkpoint(torch.load(checkpoint_path.replace(\".pth.tar\", str(i) + \".pth.tar\")), model, optimizer_class,optimizer_mask)\n",
        "  if mode == \"incorporate\":\n",
        "    f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_incorporate(loader=test_loader, model=model, device=device)\n",
        "  if mode == \"single\":\n",
        "    f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_single(loader=test_loader, model=model, device=device)\n",
        "  log_epoch(\"TEST\", i, accuracy_class, f1, dice_class, accuracy_mask, dice_mask, train_log_filename)\n",
        "\n",
        "  score = f1 + dice_class + dice_mask\n",
        "  if score > best_socre:\n",
        "    print(\"Best is: \", i)\n",
        "    best_socre = score\n",
        "    best_model_index = i\n",
        "    checkpoint = {\n",
        "      \"epoch\": i,\n",
        "      \"state_dict\": model.state_dict(),\n",
        "      \"optimizer_class\": optimizer_class.state_dict(),\n",
        "      \"optimizer_mask\": optimizer_mask.state_dict()\n",
        "    }\n",
        "    save_checkpoint(state=checkpoint,checkpoint_filename=checkpoint_path)\n",
        "\n",
        "f = open(train_log_filename, 'a+')\n",
        "f.write(f\"\\n Best model is model with index: {best_model_index}\")\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdBdB9FJjyaE"
      },
      "source": [
        "checkpoint_path = saving_directory + \"/checkpoint.pth.tar\"\n",
        "load_checkpoint(torch.load(checkpoint_path), model, optimizer_class,optimizer_mask)\n",
        "if mode == \"incorporate\":\n",
        "  f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_incorporate(loader=test_loader, model=model, device=device)\n",
        "if mode == \"single\":\n",
        "  f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_single(loader=test_loader, model=model, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}